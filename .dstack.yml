type: task
name: fast-graphrag-ollama-test

repos:
  - https://github.com/yishanyuan/25Fall-GraphRAG-Bench

python: 3.12

env:
  - OPENAI_BASE_URL=http://127.0.0.1:11434/v1
  - OPENAI_API_KEY=ollama
  - MODEL_NAME=qwen3:8b

commands:
  # 1) Install Ollama in the remote container
  - curl -fsSL https://ollama.ai/install.sh | sh

  # 2) Start the Ollama server in the background
  - nohup ollama serve > /tmp/ollama.log 2>&1 &

  # 3) Give the server time to start
  - sleep 60

  # 4) Pull the Qwen3 8B model on dstack's machine
  - ollama pull qwen3:8b

  # 5) Install fast-graphrag from the mounted repo (editable mode)
  - cd /workflow
  - uv pip install -e ".[benchmarks]"

  # 6) Run your small test script against the local Ollama server
  #    (adjust the path if your script lives in a subfolder)
  - python 395-scripts/fastgraphrag/testrun_fast-graphrag_ollama.py

resources:
  # Ask for a single NVIDIA GPU with at least 24GB VRAM
  gpu: 24GB..80GB:1
  cpu: 0..8
  memory: 48GB..
  disk: 100GB
  shm_size: 24GB
